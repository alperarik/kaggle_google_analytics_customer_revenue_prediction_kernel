{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='ignore')\n",
    "    df['year'] = df['date'].apply(lambda x: x.year)\n",
    "    df['month'] = df['date'].apply(lambda x: x.month)\n",
    "    df['day'] = df['date'].apply(lambda x: x.day)\n",
    "    df['weekday'] = df['date'].apply(lambda x: x.weekday())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_metrics(loss, val_loss):\n",
    "    fig, (ax1) = plt.subplots(1, 1, sharex='col', figsize=(20,7))\n",
    "    ax1.plot(loss, label='Train loss')\n",
    "    ax1.plot(val_loss, label='Validation loss')\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "\n",
    "def load_df(csv_path='../input/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "\n",
    "    df = pd.read_csv(csv_path, dtype={'fullVisitorId': 'str'}, nrows=nrows)\n",
    "\n",
    "    for column in JSON_COLUMNS:\n",
    "        df = df.join(pd.DataFrame(df.pop(column).apply(pd.io.json.loads).values.tolist(), index=df.index))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_df(\"train.csv\", nrows=100000)\n",
    "test = load_df(\"test.csv\", nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAIN SET')\n",
    "print('Rows: %s' % train.shape[0])\n",
    "print('Columns: %s' % train.shape[1])\n",
    "print('Features: %s' % train.columns.values)\n",
    "print()\n",
    "print('TEST SET')\n",
    "print('Rows: %s' % test.shape[0])\n",
    "print('Columns: %s' % test.shape[1])\n",
    "print('Features: %s' % test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_time_features(train)\n",
    "test = add_time_features(test)\n",
    "\n",
    "# Convert target feature to 'float' type.\n",
    "train[\"transactionRevenue\"] = train[\"transactionRevenue\"].astype('float')\n",
    "train['hits'] = train['hits'].astype(float)\n",
    "test['hits'] = test['hits'].astype(float)\n",
    "train['pageviews'] = train['pageviews'].astype(float)\n",
    "test['pageviews'] = test['pageviews'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "gp_fullVisitorId_train = train.groupby(['fullVisitorId']).agg('sum')\n",
    "gp_fullVisitorId_train['fullVisitorId'] = gp_fullVisitorId_train.index\n",
    "gp_fullVisitorId_train['mean_hits_per_day'] = gp_fullVisitorId_train.groupby(['day'])['hits'].transform('mean')\n",
    "gp_fullVisitorId_train['mean_pageviews_per_day'] = gp_fullVisitorId_train.groupby(['day'])['pageviews'].transform('mean')\n",
    "gp_fullVisitorId_train['sum_hits_per_day'] = gp_fullVisitorId_train.groupby(['day'])['hits'].transform('sum')\n",
    "gp_fullVisitorId_train['sum_pageviews_per_day'] = gp_fullVisitorId_train.groupby(['day'])['pageviews'].transform('sum')\n",
    "gp_fullVisitorId_train = gp_fullVisitorId_train[['fullVisitorId', 'mean_hits_per_day', 'mean_pageviews_per_day', 'sum_hits_per_day', 'sum_pageviews_per_day']]\n",
    "train = train.join(gp_fullVisitorId_train, on='fullVisitorId', how='inner', rsuffix='_')\n",
    "train.drop(['fullVisitorId_'], axis=1, inplace=True)\n",
    "\n",
    "# Test\n",
    "gp_fullVisitorId_test = test.groupby(['fullVisitorId']).agg('sum')\n",
    "gp_fullVisitorId_test['fullVisitorId'] = gp_fullVisitorId_test.index\n",
    "gp_fullVisitorId_test['mean_hits_per_day'] = gp_fullVisitorId_test.groupby(['day'])['hits'].transform('mean')\n",
    "gp_fullVisitorId_test['mean_pageviews_per_day'] = gp_fullVisitorId_test.groupby(['day'])['pageviews'].transform('mean')\n",
    "gp_fullVisitorId_test['sum_hits_per_day'] = gp_fullVisitorId_test.groupby(['day'])['hits'].transform('sum')\n",
    "gp_fullVisitorId_test['sum_pageviews_per_day'] = gp_fullVisitorId_test.groupby(['day'])['pageviews'].transform('sum')\n",
    "gp_fullVisitorId_test = gp_fullVisitorId_test[['fullVisitorId', 'mean_hits_per_day', 'mean_pageviews_per_day', 'sum_hits_per_day', 'sum_pageviews_per_day']]\n",
    "test = test.join(gp_fullVisitorId_test, on='fullVisitorId', how='inner', rsuffix='_')\n",
    "test.drop(['fullVisitorId_'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column that exists only in train data\n",
    "train.drop(['campaignCode'], axis=1, inplace=True)\n",
    "\n",
    "# Input missing transactionRevenue values\n",
    "train[\"transactionRevenue\"].fillna(0, inplace=True)\n",
    "\n",
    "#For submission file\n",
    "test_ids = test[\"fullVisitorId\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unwanted columns\n",
    "unwanted_columns = ['fullVisitorId', 'sessionId', 'visitId', 'visitStartTime', \n",
    "                    'browser', 'browserSize', 'browserVersion', 'flashVersion', \n",
    "                    'mobileDeviceInfo', 'mobileDeviceMarketingName', 'mobileDeviceModel', \n",
    "                    'mobileInputSelector', 'operatingSystemVersion', 'screenColors', \n",
    "                    'metro','networkDomain', 'networkLocation', 'adContent', 'campaign', \n",
    "                    'isTrueDirect', 'keyword', 'referralPath', 'source', 'operatingSystem', 'day', 'adwordsClickInfo']\n",
    "\n",
    "train.drop(unwanted_columns, axis=1, inplace=True)\n",
    "test.drop(unwanted_columns, axis=1, inplace=True)\n",
    "\n",
    "# Constant columns\n",
    "constant_columns = [c for c in train.columns if train[c].nunique()<=1]\n",
    "print('Columns with constant values: ', constant_columns)\n",
    "\n",
    "train.drop(constant_columns, axis=1, inplace=True)\n",
    "test.drop(constant_columns, axis=1, inplace=True)\n",
    "\n",
    "# Columns with more than 50% null data\n",
    "high_null_columns = [c for c in train.columns if train[c].count()<=len(train) * 0.5]\n",
    "print('Columns more than 50% null values: ', high_null_columns)\n",
    "train.drop(high_null_columns, axis=1, inplace=True)\n",
    "test.drop(high_null_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column types\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['isMobile'] = train['isMobile'].astype('object',copy=False)\n",
    "train['year'] = train['year'].astype('object',copy=False)\n",
    "train['month'] = train['month'].astype('object',copy=False)\n",
    "train['weekday'] = train['weekday'].astype('object',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column types\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['isMobile'] = test['isMobile'].astype('category',copy=False)\n",
    "test['year'] = test['year'].astype('category',copy=False)\n",
    "test['month'] = test['month'].astype('category',copy=False)\n",
    "test['weekday'] = test['weekday'].astype('category',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_column = 'transactionRevenue'\n",
    "numerical_columns = train.select_dtypes(include=[np.number]).columns.drop(class_column)\n",
    "categorical_columns = train.select_dtypes(include=[np.object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(df, df_class_name, color='r'):\n",
    "    for column in df.columns:\n",
    "        if column in numerical_columns:\n",
    "            #plt.subplots(figsize=(10,5))\n",
    "            sns.scatterplot(x=column, y=df_class_name, data=df[[column, df_class_name]])\n",
    "            plt.show()\n",
    "        \n",
    "        if column in categorical_columns:\n",
    "            #plt.subplots(figsize=(10,5))\n",
    "            sns.catplot(x=column, y=df_class_name, data=df[[column, df_class_name]], height=8)\n",
    "            plt.show()\n",
    "    \n",
    "plot_all(train, 'transactionRevenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate categorical values\n",
    "train['channelGrouping'].replace(['Paid Search', 'Display', 'Social', 'Affiliates', '(Other)'], 5*['Other'], inplace=True)\n",
    "train['continent'].replace(['Africa', 'Oceania', '(not set)'], 3*['Other'], inplace=True)\n",
    "train['medium'].replace(['(none)', 'affiliate', '(not set)'], 3*['Other'], inplace=True)\n",
    "\n",
    "#Drop multi-valued columns\n",
    "train.drop(['city', 'country', 'region', 'subContinent'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate categorical values\n",
    "test['channelGrouping'].replace(['Paid Search', 'Display', 'Social', 'Affiliates', '(Other)'], 5*['Other'], inplace=True)\n",
    "test['continent'].replace(['Africa', 'Oceania', '(not set)'], 3*['Other'], inplace=True)\n",
    "test['medium'].replace(['(none)', 'affiliate', '(not set)'], 3*['Other'], inplace=True)\n",
    "\n",
    "#Drop multi-valued columns\n",
    "test.drop(['city', 'country', 'region', 'subContinent'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(train, 'transactionRevenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('TRAIN SET')\n",
    "print('Rows: %s' % train.shape[0])\n",
    "print('Columns: %s' % train.shape[1])\n",
    "print('Features: %s' % train.columns.values)\n",
    "print()\n",
    "print('TEST SET')\n",
    "print('Rows: %s' % test.shape[0])\n",
    "print('Columns: %s' % test.shape[1])\n",
    "print('Features: %s' % test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STD_COEFFICIENT = 3\n",
    "def outlier_analysis(df):\n",
    "    columns = df.columns\n",
    "    for column in columns:\n",
    "        if column in numerical_columns:\n",
    "            std = df[column].std()\n",
    "            mean = df[column].mean()\n",
    "            non_outlier_df = df[(df[column] > mean - STD_COEFFICIENT*std) & (df[column] < mean + STD_COEFFICIENT*std)]\n",
    "            if len(non_outlier_df) > 0:\n",
    "                df = non_outlier_df\n",
    "            else:\n",
    "                print(\"column %s  : all elements outlier\"%column)\n",
    "            print(\"column %s applied\"%column)\n",
    "            print(\"new lenght: %d\" %len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_analysis(train.drop(['date','transactionRevenue'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_correlation(df, df_class):\n",
    "    for column in df.columns:\n",
    "        if column in numerical_columns:\n",
    "            corr = df[column].corr(df_class)\n",
    "            print(\"column : %s, corr : %f\"%(column, corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_correlation(train.drop(['transactionRevenue'], axis=1), train['transactionRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop negative correlation valued columns\n",
    "train.drop(['sum_hits_per_day', 'sum_pageviews_per_day'], axis=1, inplace=True)\n",
    "test.drop(['sum_hits_per_day', 'sum_pageviews_per_day'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = numerical_columns.drop('sum_hits_per_day')\n",
    "numerical_columns = numerical_columns.drop('sum_pageviews_per_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[train['date']<=datetime.date(2017, 5, 31)]\n",
    "X_val = train[train['date']>datetime.date(2017, 5, 31)]\n",
    "X_train.drop(['date'], axis=1, inplace=True)\n",
    "X_val.drop(['date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get labels\n",
    "Y_train = X_train['transactionRevenue'].values\n",
    "Y_val = X_val['transactionRevenue'].values\n",
    "X_train.drop(['transactionRevenue'], axis=1, inplace=True)\n",
    "X_val.drop(['transactionRevenue'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transform the labels\n",
    "Y_train = np.log1p(Y_train)\n",
    "Y_val = np.log1p(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_features = ['date']\n",
    "train.drop(reduce_features, axis=1, inplace=True)\n",
    "test.drop(reduce_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize numerical columns\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_val[numerical_columns] = scaler.fit_transform(X_val[numerical_columns])\n",
    "test[numerical_columns] = scaler.fit_transform(test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)\n",
    "\n",
    "submission = pd.DataFrame({\"fullVisitorId\":test_ids})\n",
    "predictions[predictions<0] = 0\n",
    "submission[\"PredictedLogRevenue\"] = predictions\n",
    "submission = submission.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n",
    "submission.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "submission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"]\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
