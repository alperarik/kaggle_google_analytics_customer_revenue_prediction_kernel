{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMNuXD6XElyS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read preprocessed data\n",
    "test = pd.read_csv('test.csv')\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_val = pd.read_csv('X_val.csv')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "Y_val = np.load('Y_val.npy')\n",
    "test_ids = np.load('test_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "5exhz5bm_CLB",
    "outputId": "e11bfc43-2846-48f3-c30c-60a306886352"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "print(test_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12Mp-UzwfBWS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qCUfCaG5282"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hf82pMWd6IpG"
   },
   "outputs": [],
   "source": [
    "#XGB parameter explanations\n",
    "\n",
    "#eta : learning rate [0,1]\n",
    "#silent : verbose 0 or 1\n",
    "#alpha L1, lambda L2 regularization\n",
    "#tree_method : exact or hist (hist is fast cause of uses binnig and caching)\n",
    "#max_depth : high value can cause overfitting\n",
    "#subsample : observations, Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n",
    "#colsample_bytree : number of columns using for observations\n",
    "#random_state : validation percentage\n",
    "\n",
    "#num_boost_round : Number of boosting iterations.\n",
    "#early_stopping_rounds : Validation error needs to decrease at least every early_stopping_rounds round(s) to continue training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample hyperparameter values\n",
    "num_boost_round = [100,300,500]\n",
    "early_stopping_rounds = [100,300,500]\n",
    "learning_rate = [0.5, 0.3, 0.1, 0.01, 0.005, 0.001]\n",
    "bagging_fraction = [0.25, 0.5, 0.75]\n",
    "feature_fraction = [0.3, 0.5, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning (*Grid)\n",
    "parameter_space_xgb = list(itertools.product(num_boost_round, early_stopping_rounds, learning_rate, bagging_fraction, feature_fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FqeQ48XqGv64"
   },
   "outputs": [],
   "source": [
    "def run_xgb(X_train, y_train, X_val, y_val, X_test, parameters):\n",
    "    params = {'objective': 'reg:linear',\n",
    "              'eval_metric': 'rmse',\n",
    "              'eta': parameters[2],\n",
    "              'max_depth': 10,\n",
    "              'subsample': parameters[3], # 0-1\n",
    "              'colsample_bytree': parameters[4], #0-1\n",
    "              'alpha':0.001,\n",
    "              'lambda':0.001,\n",
    "              'random_state': 70,\n",
    "              'silent': True}\n",
    "\n",
    "    xgb_train_data = xgb.DMatrix(X_train, y_train)\n",
    "    xgb_val_data = xgb.DMatrix(X_val, y_val)\n",
    "    xgb_submit_data = xgb.DMatrix(X_test)\n",
    "\n",
    "    model = xgb.train(params, xgb_train_data, \n",
    "                      num_boost_round=parameters[0], \n",
    "                      evals= [(xgb_train_data, 'train'), (xgb_val_data, 'valid')],\n",
    "                      early_stopping_rounds=parameters[1], \n",
    "                      verbose_eval=500\n",
    "                     )\n",
    "\n",
    "    y_pred_train = model.predict(xgb_train_data, ntree_limit=model.best_ntree_limit)\n",
    "    y_pred_val = model.predict(xgb_val_data, ntree_limit=model.best_ntree_limit)\n",
    "    y_pred_submit = model.predict(xgb_submit_data, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    print(f\"XGB : RMSE val: {rmse(y_val, y_pred_val)}  - RMSE train: {rmse(y_train, y_pred_train)}\")\n",
    "    return y_pred_submit, model, rmse(y_val, y_pred_val), rmse(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions = []\n",
    "filename = \"xgb.csv\"\n",
    "with open(filename,'a', newline='') as resultFile:\n",
    "    wr = csv.writer(resultFile, dialect='excel')\n",
    "    wr.writerow([\"index\", \"num_boost_round\", \"early_stopping_rounds\", \"learning_rate\", \"bagging_fraction\", \"feature_fraction\",\"rmse_val\", \"rmse_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Hxwr4AAHO7K"
   },
   "outputs": [],
   "source": [
    "print(\"parameter_space_xgb : %d\"%len(parameter_space_xgb))\n",
    "for index, p in tqdm(enumerate(parameter_space_xgb)):\n",
    "    try:\n",
    "        xgb_preds, xgb_model, rmse_val, rmse_train = run_xgb(X_train, Y_train, X_val, Y_val, test, p)\n",
    "        xgb_predictions.append(xgb_preds)\n",
    "        with open(filename,'a', newline='') as resultFile:\n",
    "            wr = csv.writer(resultFile, dialect='excel')\n",
    "            wr.writerow([index, p[0], p[1], p[2], p[3], p[4], rmse_val, rmse_train])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save XGB predictions\n",
    "np.save(\"xgb_predictions.npy\", np.array(xgb_predictions))\n",
    "del  xgb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample hyperparameter values\n",
    "num_iterations = [500,1000,2500]\n",
    "num_boost_round = [100,300,500]\n",
    "early_stopping_rounds = [100,300,500]\n",
    "learning_rate = [0.5, 0.3, 0.1, 0.01, 0.005, 0.001]\n",
    "num_leaves = [20,30,50]\n",
    "bagging_fraction = [0.25, 0.5, 0.75]\n",
    "feature_fraction = [0.3, 0.5, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning (*Grid)\n",
    "parameter_space_lgb = list(itertools.product(num_iterations, num_boost_round, early_stopping_rounds, learning_rate, num_leaves, bagging_fraction, feature_fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B4Ie7h6HZUZ"
   },
   "outputs": [],
   "source": [
    "def run_lgb(X_train, y_train, X_val, y_val, X_test, parameters):\n",
    "    \n",
    "    params = {\n",
    "        \"objective\" : \"regression_l1\",\n",
    "        \"num_iterations\" : parameters[0],\n",
    "        \"learning_rate\" : parameters[3],\n",
    "        \"num_leaves\" : parameters[4],\n",
    "        \"num_threads\" : 4,\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"bagging_fraction\" : parameters[5], #subsample\n",
    "        \"feature_fraction\" : parameters[6], #colsample_bytree\n",
    "        \"verbosity\" : -1,\n",
    "    }\n",
    "    \n",
    "    lgb_train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    lgb_val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(params, lgb_train_data, \n",
    "                      num_boost_round=parameters[1],\n",
    "                      valid_sets=[lgb_train_data, lgb_val_data],\n",
    "                      early_stopping_rounds=parameters[2],\n",
    "                      verbose_eval=500\n",
    "                     )\n",
    "\n",
    "    y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "    y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    y_pred_submit = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    #print(f\"LGBM: RMSE val: {rmse(y_val, y_pred_val)}  - RMSE train: {rmse(y_train, y_pred_train)}\")\n",
    "    return y_pred_submit, model, rmse(y_val, y_pred_val), rmse(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_predictions = []\n",
    "filename = \"lgb.csv\"\n",
    "\n",
    "with open(filename,'a', newline='') as resultFile:\n",
    "    wr = csv.writer(resultFile, dialect='excel')\n",
    "    wr.writerow([\"index\", \"num_iterations\", \"num_boost_round\", \"early_stopping_rounds\", \"learning_rate\", \"num_leaves\", \"bagging_fraction\", \"feature_fraction\",\"rmse_val\", \"rmse_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, p in tqdm(enumerate(parameter_space_lgb)):\n",
    "    try:\n",
    "        lgb_preds, lgb_model, rmse_val, rmse_train = run_lgb(X_train, Y_train, X_val, Y_val, test, p)\n",
    "        lgb_predictions.append(lgb_preds)\n",
    "        with open(filename,'a', newline='') as resultFile:\n",
    "            wr = csv.writer(resultFile, dialect='excel')\n",
    "            wr.writerow([index, p[0], p[1], p[2], p[3], p[4], p[5], p[6], rmse_val, rmse_train])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save LGB predictions\n",
    "np.save(\"lgb_predictions.npy\", np.array(lgb_predictions))\n",
    "del  lgb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load predictions\n",
    "xgb_predictions = np.load(\"xgb_predictions.npy\")\n",
    "lgb_predictions = np.load(\"lgb_predictions.npy\")\n",
    "\n",
    "#select least loss valued prediction\n",
    "xgb_pred = xgb_predictions[0] #sample\n",
    "lgb_pred = lgb_predictions[0] #sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1U3fpJTpyMX"
   },
   "outputs": [],
   "source": [
    "ensemble_preds_lgb_90_xgb_10 = 0.90 * lgb_preds + 0.10 * xgb_preds\n",
    "ensemble_preds_lgb_80_xgb_20 = 0.80 * lgb_preds + 0.20 * xgb_preds\n",
    "ensemble_preds_lgb_70_xgb_30 = 0.70 * lgb_preds + 0.30 * xgb_preds\n",
    "ensemble_preds_lgb_60_xgb_40 = 0.60 * lgb_preds + 0.40 * xgb_preds\n",
    "ensemble_preds_lgb_50_xgb_50 = 0.50 * lgb_preds + 0.50 * xgb_preds\n",
    "ensemble_preds_lgb_40_xgb_60 = 0.40 * lgb_preds + 0.60 * xgb_preds\n",
    "ensemble_preds_lgb_30_xgb_70 = 0.30 * lgb_preds + 0.70 * xgb_preds\n",
    "ensemble_preds_lgb_20_xgb_80 = 0.20 * lgb_preds + 0.80 * xgb_preds\n",
    "ensemble_preds_lgb_10_xgb_90 = 0.10 * lgb_preds + 0.90 * xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VuVp1GtA6P01"
   },
   "outputs": [],
   "source": [
    "predictions={\n",
    "    'xgb_preds' : xgb_preds,\n",
    "    'lgb_preds' : lgb_preds,\n",
    "    'ensemble_preds_lgb_90_xgb_10' : ensemble_preds_lgb_90_xgb_10,\n",
    "    'ensemble_preds_lgb_80_xgb_20' : ensemble_preds_lgb_80_xgb_20,\n",
    "    'ensemble_preds_lgb_70_xgb_30' : ensemble_preds_lgb_70_xgb_30,\n",
    "    'ensemble_preds_lgb_60_xgb_40' : ensemble_preds_lgb_60_xgb_40,\n",
    "    'ensemble_preds_lgb_50_xgb_50' : ensemble_preds_lgb_50_xgb_50,\n",
    "    'ensemble_preds_lgb_40_xgb_60' : ensemble_preds_lgb_40_xgb_60,\n",
    "    'ensemble_preds_lgb_30_xgb_70' : ensemble_preds_lgb_30_xgb_70,\n",
    "    'ensemble_preds_lgb_20_xgb_80' : ensemble_preds_lgb_20_xgb_80,\n",
    "    'ensemble_preds_lgb_10_xgb_90' : ensemble_preds_lgb_10_xgb_90\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiGFItcTqPIM"
   },
   "outputs": [],
   "source": [
    "for k,v in predictions.items():\n",
    "  submission = pd.DataFrame({\"fullVisitorId\":test_ids})\n",
    "  v[v<0] = 0\n",
    "  submission[\"PredictedLogRevenue\"] = v\n",
    "  submission = submission.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n",
    "  submission.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "  submission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"]\n",
    "  submission.to_csv(\"submission_%s.csv\"%k, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Google Analytics Customer Revenue Prediction XGBoost",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
